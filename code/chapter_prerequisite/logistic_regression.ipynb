{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard Logistic Regression implemented by numpy\n",
    "\n",
    "# import numpy as np\n",
    "# class LogisticRegression:\n",
    "#     def __init__(self, learning_rate=0.01, epoch=100):\n",
    "#         self.learning_rate = learning_rate\n",
    "#         self.epoch = epoch\n",
    "#         self.weights = None\n",
    "#         self.bias = None\n",
    "\n",
    "#     def sigmoid(self, z):\n",
    "#         return 1 / (1 + np.exp(-z))\n",
    "\n",
    "#     def fit(self, X, y):\n",
    "#         n_samples, n_features = X.shape\n",
    "#         self.weights = np.zeros(n_features)\n",
    "#         self.bias = 0\n",
    "\n",
    "#         # Gradient descent\n",
    "#         for _ in range(self.epoch):\n",
    "#             linear_model = np.dot(X, self.weights) + self.bias\n",
    "#             y_predicted = self.sigmoid(linear_model)\n",
    "\n",
    "#             # calculate gradients\n",
    "#             dw = (1 / n_samples) * np.dot(X.T, (y_predicted - y))\n",
    "#             db = (1 / n_samples) * np.sum(y_predicted - y)\n",
    "\n",
    "#             # update parameters\n",
    "#             self.weights -= self.learning_rate * dw\n",
    "#             self.bias -= self.learning_rate * db\n",
    "\n",
    "#     def predict(self, X, threshold=0.5):\n",
    "#         z = np.dot(X, self.weights) + self.bias\n",
    "#         y_predicted = self.sigmoid(z)\n",
    "#         return [1 if i > threshold else 0 for i in y_predicted]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For simplifying, we implemente the logistic regression model through torch.\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "num_epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CancerDataset(Dataset):\n",
    "    def __init__(self, data, targets):\n",
    "        scaler = StandardScaler()\n",
    "        self.data = torch.tensor(scaler.fit_transform(data), dtype=torch.float32)\n",
    "        self.targets = torch.tensor(targets, dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.targets[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义PyTorch逻辑回归模型（显式实现sigmoid）\n",
    "class LogisticRegression(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(LogisticRegression, self).__init__()\n",
    "        self.linear = nn.Linear(input_dim, 1)\n",
    "        nn.init.xavier_uniform_(self.linear.weight)\n",
    "        nn.init.zeros_(self.linear.bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 只返回线性输出，不应用sigmoid\n",
    "        return self.linear(x)\n",
    "\n",
    "    def sigmoid(self, z):\n",
    "        return 1 / (1 + torch.exp(-z))\n",
    "\n",
    "\n",
    "def binary_cross_entropy_with_logits(logits, targets):\n",
    "    probs = torch.sigmoid(logits)\n",
    "    epsilon = 1e-7\n",
    "    probs = torch.clamp(probs, epsilon, 1 - epsilon)\n",
    "    loss = -torch.mean(\n",
    "        targets * torch.log(probs) + (1 - targets) * torch.log(1 - probs)\n",
    "    )\n",
    "    return loss.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datasets\n",
    "cancer = load_breast_cancer()\n",
    "X = cancer.data\n",
    "y = cancer.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "train_dataset = CancerDataset(X_train, y_train)\n",
    "test_dataset = CancerDataset(X_test, y_test)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/100], Loss: 0.2333\n",
      "Epoch [20/100], Loss: 0.1672\n",
      "Epoch [30/100], Loss: 0.1407\n",
      "Epoch [40/100], Loss: 0.1259\n",
      "Epoch [50/100], Loss: 0.1165\n",
      "Epoch [60/100], Loss: 0.1096\n",
      "Epoch [70/100], Loss: 0.1043\n",
      "Epoch [80/100], Loss: 0.0999\n",
      "Epoch [90/100], Loss: 0.0965\n",
      "Epoch [100/100], Loss: 0.0936\n"
     ]
    }
   ],
   "source": [
    "input_dim = X_train.shape[1]\n",
    "model = LogisticRegression(input_dim)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for inputs, labels in train_loader:\n",
    "        logits = model(inputs)\n",
    "        loss = binary_cross_entropy_with_logits(logits, labels)\n",
    "        total_loss += loss.item() * inputs.size(0)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    avg_loss = total_loss / len(train_loader.dataset)\n",
    "\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.9825\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        logits = model(inputs)\n",
    "        probs = model.sigmoid(logits)\n",
    "        preds = (probs > 0.5).float()\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "accuracy = accuracy_score(all_labels, all_preds)\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gen",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
