{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "cd8c8a75",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-03T07:10:53.507526Z",
     "start_time": "2023-12-03T07:10:53.503757Z"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e3c2a0a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[33mswanlab\u001b[0m\u001b[0m: You have already initialized a run, the init function will be ignored\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import swanlab\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "SWANLAB_API_KEY = os.getenv(\"SWANLAB_API_KEY\")\n",
    "\n",
    "# https://docs.swanlab.cn/api/py-init.html\n",
    "exp = swanlab.init(\n",
    "    project=\"Gerative-Model-Foundamental-Knowledge\",\n",
    "    experiment_name=\"VAE\",\n",
    "    description=\"VAE algo in mnist datasets\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "891f9f69",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-26T10:20:35.293960Z",
     "start_time": "2023-11-26T10:20:34.804258Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.utils.data\n",
    "from torch import nn, optim\n",
    "from torch.nn import functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.utils import save_image\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11e1d594",
   "metadata": {},
   "source": [
    "## from AE to VAE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77add427",
   "metadata": {},
   "source": [
    "- references\n",
    "  - https://arxiv.org/pdf/1312.6114.pdf\n",
    "- AE 一般都是降维的，AE 一般用来压缩重构，VAE 则是用来做 generative，做图像生成；\n",
    "  - latent/smaller/compressed representation；\n",
    "  - 关于 latent variables（$z$）建模：latent variable models\n",
    "    - latent variable：hidden & 不可直接被观察到的变量（variables）；\n",
    "      - 比如对健康/智商等的评估，通过一组可观测的指标来 infer；\n",
    "    - LDM：Latent Diffusion Model\n",
    "  - AE 关心的是 z（latent vectors/variables），前半部分（encoder），decoder 只是用来监督保证学到一个很好的 encoder；\n",
    "    - VAE 关心的则是 generating 的过程；\n",
    "- 总结下来\n",
    "  - input: $x$, hidden: $\\mu, \\sigma$, output: $\\tilde x$\n",
    "    - $x$：data，可观测的；latent variable models 假设的是，latent space 中的 $z$ 导致了 $x$\n",
    "    - 概率图的角度就是 $z\\rightarrow x$（generative models 的 generation process）\n",
    "  - Encoder: $q_\\phi(z|x), x\\rightarrow z$\n",
    "  - latent distribution：$z=\\mu+\\sigma\\odot \\epsilon$\n",
    "  - Decoder: $p_\\theta(x|z), z\\rightarrow \\tilde x$\n",
    "- references\n",
    "  - https://kvfrans.com/variational-autoencoders-explained/\n",
    "  - https://github.com/pytorch/examples/blob/main/vae/main.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "13bddb3c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-15T14:10:39.267691Z",
     "start_time": "2023-11-15T14:10:39.258057Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://kvfrans.com/content/images/2016/08/autoenc.jpg\" width=\"500\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url=\"https://kvfrans.com/content/images/2016/08/autoenc.jpg\", width=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c1b71474",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-15T14:10:58.800735Z",
     "start_time": "2023-11-15T14:10:58.791244Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://kvfrans.com/content/images/2016/08/vae.jpg\" width=\"500\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url=\"https://kvfrans.com/content/images/2016/08/vae.jpg\", width=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5442acd1",
   "metadata": {},
   "source": [
    "### 网络结构\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15f221c2",
   "metadata": {},
   "source": [
    "- Encoder & Decoder\n",
    "  - Encoder：$q(z|x)$（神经网络参数为 $\\phi$） => $q_\\phi(z|x)$\n",
    "    - inference network，推断 latent variables $z$\n",
    "  - Decoder: $p(x|z)$（神经网络参数为 $\\theta$）=> $p_\\theta(x|z)$\n",
    "    - generate network\n",
    "- latent space\n",
    "  - 编码器的输出，是两个向量，一个是均值向量 $\\mu$，一个是标准差向量 $\\sigma$，它们长度相同，它们一起定义了输入数据在 latent space 中的 representation；\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9557a4a",
   "metadata": {},
   "source": [
    "## loss function\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa5565d4",
   "metadata": {},
   "source": [
    "$$\n",
    "\\mathcal L(\\theta, \\phi;\\mathbf x, \\mathbf z)=\\underbrace{\\mathbb E_{q_\\phi(z|x)}\\left[\\log p_\\theta(x|z)\\right]}_{\\text{reconstruction loss}}-\\underbrace{D_{KL}\\left(q_\\phi(z|x)\\|p(z)\\right)}_{\\text{stay close to Normal(0,1)}}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c101e062",
   "metadata": {},
   "source": [
    "### variational inference\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e17497f",
   "metadata": {},
   "source": [
    "- 我们想要计算 $z$ 的后验概率\n",
    "\n",
    "  $$\n",
    "  p_\\theta(z|x)=\\frac{p_\\theta(x|z)p_\\theta(z)}{p_\\theta(x)}=\\frac{p_\\theta(x|z)p_\\theta(z)}{\\int p_\\theta(x, z)dz}\n",
    "  $$\n",
    "\n",
    "  - 比较难计算的是分母的 $p_\\theta(x)$（marginal likelihood or evidence），有如下的两种计算思路：\n",
    "    - Monte Carlo sampling\n",
    "    - variational inference\n",
    "\n",
    "- 现如果要计算 **后验 $p_\\theta(z|x)$，我们引入 $q_\\phi(z)$**（也是一个概率分布 $\\sum_zq_\\phi(z)=1$） 来逼近，\n",
    "\n",
    "$$\n",
    "\\begin{split}\n",
    "KL\\left[q_\\phi(z)\\|p_\\theta(z|x)\\right]&=-\\sum_zq_\\phi(z)\\log \\frac{p_\\theta(z|x)}{q_\\phi(z)}\\\\\n",
    "&=-\\underset{z}{\\sum} q_{\\phi}(z) \\log \\bigg( \\frac{p_{\\theta}(x,z)}{q_{\\phi}(z)} \\cdot \\frac{1}{p_{\\theta}(x)} \\bigg) \\\\\n",
    "&= -\\underset{z}{\\sum} q_{\\phi}(z) \\bigg( \\log\\frac{p_{\\theta}(x,z)}{q_{\\phi}(z)} - \\log p_{\\theta}(x) \\bigg) \\\\\n",
    "&= -\\underset{z}{\\sum} q_{\\phi}(z) \\log \\frac{p_{\\theta}(x,z)}{q_{\\phi}(z)} + \\underset{z}{\\sum} q_{\\phi}(z) \\log p_{\\theta}(x)\\\\\n",
    "&==\n",
    "-\\underset{z}{\\sum} q_{\\phi}(z) \\log \\frac{p_{\\theta}(x,z)}{q_{\\phi}(z)} + \\log p_{\\theta}(x)\n",
    "\\end{split}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\log p_{\\theta}(x) = \\underbrace{KL[q_{\\phi}(z) \\lVert p_{\\theta}(z \\lvert x)]}_{\\text{kl div}} + \\underbrace{\\underset{z}{\\sum} q_{\\phi}(z) \\log \\frac{p_{\\theta}(x,z)}{q_{\\phi}(z)}}_{\\text{variational lower bound /ELBO}}\\\\\n",
    "\\underbrace{\\underset{z}{\\sum} q_{\\phi}(z) \\log \\frac{p_{\\theta}(x,z)}{q_{\\phi}(z)}}_{\\text{variational lower bound /ELBO}}=\\log p_{\\theta}(x)-\\underbrace{KL[q_{\\phi}(z) \\lVert p_{\\theta}(z \\lvert x)]}_{\\text{kl div}}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "133d7f92",
   "metadata": {},
   "source": [
    "### ELBO\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "108d0f6c",
   "metadata": {},
   "source": [
    "- Evidence ($p(x)$) Lower BOund\n",
    "\n",
    "  $$\n",
    "  \\begin{align}\n",
    "  \\mathcal{L} &= \\underset{z}{\\sum} q_{\\phi}(z) \\log \\frac{p_{\\theta}(x,z)}{q_{\\phi}(z)} \\\\\n",
    "  &= \\mathbb{E}_{q_{\\phi}(z)} \\log \\frac{p_{\\theta}(x,z)}{q_{\\phi}(z)}\n",
    "  \\end{align}\n",
    "  $$\n",
    "\n",
    "  - 因为 KL div 非负，因此有 $\\log p_\\theta(x)\\geq \\mathcal L$，$\\mathcal L$ 是 marginal log likelihood 的 lower bound\n",
    "  - variational inference 聚焦在如何提升 ELBO 而不是最大似然；\n",
    "    - 最大化 ELBO 的过程，也是最大化 $\\log p_{\\theta}(x)$ （maximizing the evidence $p(x)$） 和最小化 $\\underbrace{KL[q_{\\phi}(z) \\lVert p_{\\theta}(z \\lvert x)]}_{\\text{kl div}}$ 的过程\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c94a2f85",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-19T10:49:10.329287Z",
     "start_time": "2023-11-19T10:49:10.320036Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://jejjohnson.github.io/research_notebook/_images/elbo_inequality.png\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://jejjohnson.github.io/research_notebook/content/notes/concepts/jensens.html\n",
    "Image(url=\"https://jejjohnson.github.io/research_notebook/_images/elbo_inequality.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97fe9803",
   "metadata": {},
   "source": [
    "### VAE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0e1fc31",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{align}\n",
    "\\mathcal{L} &= \\underset{z}{\\sum} q_{\\phi}(z) \\log \\frac{p_{\\theta}(x,z)}{q_{\\phi}(z)} \\\\\n",
    "&= \\mathbb{E}_{q_{\\phi}(z)} \\log \\frac{p_{\\theta}(x,z)}{q_{\\phi}(z)} \\\\\n",
    "&= \\mathbb{E}_{q_{\\phi}(z)} \\log \\frac{p_{\\theta}(x \\lvert z)p_{\\theta}(z)}{q_{\\phi}(z)} \\\\\n",
    "&= \\mathbb{E}_{q_{\\phi}(z)} \\log p_{\\theta}(x \\lvert z) +  \\mathbb{E}_{q_{\\phi}(z)} \\log \\frac{p_{\\theta}(z)}{q_{\\phi}(z)} \\\\\n",
    "&= \\mathbb{E}_{q_{\\phi}(z)} \\log p_{\\theta}(x \\lvert z) - KL[q_{\\phi}(z) \\lVert p_{\\theta}(z)]\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "- 因为我们选择 $q_\\phi(z)$ 就是为了逼近后验 $p_\\theta(z|x)$, 我们选择让 $z$ conditional on $x$，也即是$q_\\phi(z)=q_\\phi(z|x)$，因此\n",
    "\n",
    "  $$\n",
    "  \\mathcal L=\\underbrace{\\mathbb{E}_{q_{\\phi}(z|x)} \\log p_{\\theta}(x \\lvert z)}_{\\text{reconstruction loss}}\\underbrace{- KL[q_{\\phi}(z|x) \\lVert p_{\\theta}(z)]}_{\\text{regularization}}\n",
    "  $$\n",
    "\n",
    "  - $p_\\theta(z)=\\mathcal N(0,I)$（diagonal unit Gaussian），先验的假设；\n",
    "\n",
    "- 该公式便是著名的 VAE 的最大化的目标（最大化 elbo）；\n",
    "  - 注意是最大化哈，最大化的右边不是 loss，对其取负号，表示的才是要最小化的目标；\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c56369a7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-26T09:06:48.130975Z",
     "start_time": "2023-11-26T09:06:48.114592Z"
    }
   },
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "    def __init__(self, input_dim=784, h_dim=400, z_dim=20):\n",
    "        super(VAE, self).__init__()\n",
    "        # 28*28 ==> 784\n",
    "        # fc1 => fc21\n",
    "        # fc1 => fc22\n",
    "        self.fc1 = nn.Linear(input_dim, h_dim)\n",
    "\n",
    "        # mu\n",
    "        self.fc21 = nn.Linear(h_dim, z_dim)\n",
    "        # logvar\n",
    "        self.fc22 = nn.Linear(h_dim, z_dim)\n",
    "\n",
    "        self.fc3 = nn.Linear(z_dim, h_dim)\n",
    "        # to 784: 28*28\n",
    "        self.fc4 = nn.Linear(h_dim, input_dim)\n",
    "\n",
    "    def encode(self, x):\n",
    "        h1 = F.relu(self.fc1(x))\n",
    "        return self.fc21(h1), self.fc22(h1)\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        # z = mu + eps*std\n",
    "        return mu + eps * std\n",
    "\n",
    "    def decode(self, z):\n",
    "        h3 = F.relu(self.fc3(z))\n",
    "        # sigmoid: 0-1 之间，后边会用到 BCE loss 计算重构 loss（reconstruction loss）\n",
    "        return torch.sigmoid(self.fc4(h3))\n",
    "\n",
    "    def forward(self, x):\n",
    "        mu, logvar = self.encode(x.view(-1, 784))\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        return self.decode(z), mu, logvar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "319894bb",
   "metadata": {},
   "source": [
    "$$\n",
    "\\frac{\\log\\sigma^2}2=\\log \\sigma\\\\\n",
    "\\exp\\left(\\frac{\\log\\sigma^2}2\\right)=\\exp(\\log \\sigma)=\\sigma\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d9fd63b0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-19T10:54:03.141216Z",
     "start_time": "2023-11-19T10:54:02.769386Z"
    }
   },
   "outputs": [],
   "source": [
    "vae = VAE()\n",
    "inputs = torch.randn(1, 28 * 28)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8449d3e",
   "metadata": {},
   "source": [
    "## training\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c4c21a5",
   "metadata": {},
   "source": [
    "### sampling: reparameterization trick\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "45ef33ab",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-15T15:32:51.898719Z",
     "start_time": "2023-11-15T15:32:51.887972Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://miro.medium.com/v2/resize:fit:4800/format:webp/1*I9532-09gKnRR43acCFedQ.png\" width=\"400\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(\n",
    "    url=\"https://miro.medium.com/v2/resize:fit:4800/format:webp/1*I9532-09gKnRR43acCFedQ.png\",\n",
    "    width=400,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0d1a23e",
   "metadata": {},
   "source": [
    "- 重参数化技巧使得反向传播成为可能；\n",
    "  - 在 VAE 中，我们希望从潜在空间（latent space）中抽取样本，这个潜在空间通常是由神经网络输出的一些参数（如均值和方差）定义的正态分布。然而，直接从这种分布中抽取样本是一个随机过程，这使得无法直接对其进行反向传播，因为梯度无法穿过随机节点。\n",
    "- 重参数化技巧，它的基本思想是将随机抽样过程重写为一个可微分的操作，具体操作如下：\n",
    "  - 分离随机性和网络参数，$q_\\phi(z|x)$ 预测 $\\mu,\\sigma$, 我们不再是从该参数化的分布中直接进行采样，而是从一个标准正态分布 $\\mathcal N(0,1)$ 中抽取一个随机噪声，$\\epsilon$\n",
    "  - 重参数化转换，基于上一步，我们可以计算 latent variable $z=\\mu+\\sigma\\odot \\epsilon=g_{\\mu,\\sigma}(\\epsilon)$ （element-wise product）\n",
    "    - 这里的关键是噪声 $\\epsilon$ 是随机的，但是一旦抽取，它就是一个固定的值，使得整个表达式变得可微分。\n",
    "    - $z=\\mu+\\sigma\\odot\\epsilon$ 而不是 $z\\sim q_\\phi(z|x)$，直接取值，而不是采样；\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "77a4c59d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-15T15:35:55.969675Z",
     "start_time": "2023-11-15T15:35:55.959474Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://i.stack.imgur.com/TzX3I.png\" width=\"400\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url=\"https://i.stack.imgur.com/TzX3I.png\", width=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3765c460",
   "metadata": {},
   "source": [
    "### training loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5e5d8e0",
   "metadata": {},
   "source": [
    "```\n",
    "reconst_loss = F.binary_cross_entropy(x_reconst, x, size_average=False)\n",
    "kl_div = - 0.5 * torch.sum(1 + log_var - mu.pow(2) - log_var.exp())\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f400a1b8",
   "metadata": {},
   "source": [
    "### inference/generating\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf256997",
   "metadata": {},
   "source": [
    "```\n",
    "# 从标准正态分布中进行采样\n",
    "z = torch.randn(batch_size, z_dim).to(device)\n",
    "out = model.decode(z).view(-1, 1, 28, 28)\n",
    "```\n",
    "\n",
    "- 编码空间（潜在空间）通常是连续的，可以从潜在空间中随机采样并通过解码器生成新的图像。\n",
    "  - samaple from a distribution\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8a60e48",
   "metadata": {},
   "source": [
    "## coding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0f1e3ac7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-26T09:03:10.210186Z",
     "start_time": "2023-11-26T09:03:10.196980Z"
    }
   },
   "outputs": [],
   "source": [
    "# Device configuration\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Create a directory if not exists\n",
    "sample_dir = \"samples\"\n",
    "if not os.path.exists(sample_dir):\n",
    "    os.makedirs(sample_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7ad47306",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-26T09:03:14.427041Z",
     "start_time": "2023-11-26T09:03:14.411493Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1ac24779",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-26T11:50:57.802376Z",
     "start_time": "2023-11-26T11:50:57.796000Z"
    }
   },
   "outputs": [],
   "source": [
    "# Hyper-parameters\n",
    "image_size = 784  # 28*28\n",
    "h_dim = 400\n",
    "z_dim = 20\n",
    "num_epochs = 20\n",
    "batch_size = 128\n",
    "learning_rate = 3e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b705b118",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-26T09:29:43.684303Z",
     "start_time": "2023-11-26T09:29:43.598493Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n",
      "100.0%\n",
      "100.0%\n",
      "100.0%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 28, 28])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MNIST dataset\n",
    "dataset = datasets.MNIST(\n",
    "    root=\"./data\", train=True, transform=transforms.ToTensor(), download=True\n",
    ")\n",
    "# Data loader\n",
    "data_loader = torch.utils.data.DataLoader(\n",
    "    dataset=dataset, batch_size=batch_size, shuffle=True\n",
    ")\n",
    "dataset[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2765afaf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-26T09:06:34.393504Z",
     "start_time": "2023-11-26T09:06:34.282304Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n",
      "100.0%\n",
      "100.0%\n",
      "100.0%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 28, 28])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# FashionMNIST dataset\n",
    "dataset = datasets.FashionMNIST(\n",
    "    root=\"./data\", train=True, transform=transforms.ToTensor(), download=True\n",
    ")\n",
    "\n",
    "# Data loader\n",
    "data_loader = torch.utils.data.DataLoader(\n",
    "    dataset=dataset, batch_size=batch_size, shuffle=True\n",
    ")\n",
    "dataset[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "536fee3c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-26T11:53:31.098907Z",
     "start_time": "2023-11-26T11:53:31.089076Z"
    }
   },
   "outputs": [],
   "source": [
    "model = VAE().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "9a5361b5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-26T11:55:06.154014Z",
     "start_time": "2023-11-26T11:53:33.064754Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/little1d/Desktop/Dev_env/miniconda3/envs/gen/lib/python3.10/site-packages/torch/nn/_reduction.py:51: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[1/20], Step [200/469], total Loss: 38255.6641=Reconst Loss: 36268.3516+KL Div: 1987.3140\n",
      "Epoch[1/20], Step [400/469], total Loss: 35347.3086=Reconst Loss: 33216.9102+KL Div: 2130.3987\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Image' object has no attribute 'view'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[57], line 51\u001b[0m\n\u001b[1;32m     49\u001b[0m out, _, _ \u001b[38;5;241m=\u001b[39m model(x)\n\u001b[1;32m     50\u001b[0m out \u001b[38;5;241m=\u001b[39m swanlab\u001b[38;5;241m.\u001b[39mImage(out, caption\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreconst-\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.png\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(epoch \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m---> 51\u001b[0m x_concat \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([x\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m28\u001b[39m, \u001b[38;5;241m28\u001b[39m), \u001b[43mout\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m28\u001b[39m, \u001b[38;5;241m28\u001b[39m)], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)\n\u001b[1;32m     52\u001b[0m reconst_image\u001b[38;5;241m.\u001b[39mappend(out)\n\u001b[1;32m     53\u001b[0m \u001b[38;5;66;03m# 16*16\u001b[39;00m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;66;03m# save_image(\u001b[39;00m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m#     x_concat, os.path.join(sample_dir, \"reconst-{}.png\".format(epoch + 1))\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m# )\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Image' object has no attribute 'view'"
     ]
    }
   ],
   "source": [
    "sample_image = []\n",
    "reconst_image = []\n",
    "for epoch in range(num_epochs):\n",
    "    # training\n",
    "    for i, (x, _) in enumerate(data_loader):\n",
    "        # Forward pass\n",
    "        x = x.to(device).view(-1, image_size)\n",
    "        x_reconst, mu, log_var = model(x)\n",
    "\n",
    "        # Compute reconstruction loss and kl divergence\n",
    "        #\n",
    "        reconst_loss = F.binary_cross_entropy(x_reconst, x, size_average=False)\n",
    "        kl_div = -0.5 * torch.sum(1 + log_var - mu.pow(2) - log_var.exp())\n",
    "\n",
    "        # Backprop and optimize\n",
    "        loss = reconst_loss + kl_div\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        swanlab.log(\n",
    "            {\"reconst_loss\": reconst_loss, \"kl_div\": kl_div, \"training_loss\": loss}\n",
    "        )\n",
    "\n",
    "        if (i + 1) % 200 == 0:\n",
    "            print(\n",
    "                \"Epoch[{}/{}], Step [{}/{}], total Loss: {:.4f}=Reconst Loss: {:.4f}+KL Div: {:.4f}\".format(\n",
    "                    epoch + 1,\n",
    "                    num_epochs,\n",
    "                    i + 1,\n",
    "                    len(data_loader),\n",
    "                    loss.item(),\n",
    "                    reconst_loss.item(),\n",
    "                    kl_div.item(),\n",
    "                )\n",
    "            )\n",
    "\n",
    "    # sampling/generating\n",
    "    with torch.no_grad():\n",
    "        # 从标准正态分布中进行采样\n",
    "        z = torch.randn(batch_size, z_dim).to(device)\n",
    "        out = model.decode(z).view(-1, 1, 28, 28)\n",
    "        out = swanlab.Image(out, caption=\"sampled-{}.png\".format(epoch + 1))\n",
    "        # 16*8\n",
    "        sample_image.append(out)\n",
    "        # save_image(out, os.path.join(sample_dir, \"sampled-{}.png\".format(epoch + 1)))\n",
    "\n",
    "        # Save the reconstructed images\n",
    "        out, _, _ = model(x)\n",
    "        out = swanlab.Image(out, caption=\"reconst-{}.png\".format(epoch + 1))\n",
    "        x_concat = torch.cat([x.view(-1, 1, 28, 28), out.view(-1, 1, 28, 28)], dim=3)\n",
    "        reconst_image.append(out)\n",
    "        # 16*16\n",
    "        # save_image(\n",
    "        #     x_concat, os.path.join(sample_dir, \"reconst-{}.png\".format(epoch + 1))\n",
    "        # )\n",
    "\n",
    "exp.log({\"sample_images\": sample_image}, {\"reconst_images\": reconst_image})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7074a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "swanlab.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
